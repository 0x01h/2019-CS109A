var tipuesearch = {"pages":[{"title":"GitHub Page","text":"All course content (except Lectures 2-4, 12-13, and 15-17) is in: GitHub repo We suggest that you clone this repository.","tags":"pages","url":"pages/github.html"},{"title":"Schedule","text":"Week Lecture (Mon) Lecture (Wed) Lab (Thu-Fri) Advanced Section (Wed) Assignment (R:Released Tue - D:Due Wed) 1 Lecture 0: What is Data Science? Lab 1: Introduction to Python and its Numerical Stack R:HW0 2 Lecture 1: Data, Summaries and Visuals Lecture 2: Data Engineering - The Grammar of Data Lab 2: Python for Data Collection and Cleaning (BeautifulSoup and Pandas) R:HW1 - D:HW0 3 Lecture 3: Effective Exploratory Data Analysis and Visualization Lecture 4: Linear Regression, kNN Regression and Inference Lab 3: Scikit-learn for Simple Linear Regression Advanced Section 1: Linear Algebra and Hypothesis Testing R:HW2 - D:HW1 4 Lecture 5: Linear Regression, Confidence Intervals and Standard Errors Lecture 6: Multiple Linear Regression, Polynomial Regression and Model Selection Lab 4: Multiple Linear Regression and Polynomial Regression Advanced Section 2: Model Selection and Information Criteria - Akaike Information Criterion (AIC) R:HW3 - D:HW2 5 Lecture 7: Regularization Lecture 8: High Dimensionality and Principal Component Analysis (PCA) Lab 5: Regularization and Cross-Validation Advanced Section 3: Methods of Regularization and its Justifications R:HW4(individual) D:HW3 6 No Lecture: Columbus Day Lecture 9: Visualization for Communication No Lab No Advanced Section No Assignment 7 Lecture 10: Logistic Regression 1 Lecture 11: Logistic Regression 2 Lab 6: Logistic Regression and PCA Advanced Section 4: Methods of Dimensionality Reduction - PCA R:HW5 - D:HW4 8 Lecture 12: Neural Networks 1 - Perceptron and Back Propagation Lecture 13: k-NN for Classification and Dealing with Missingness Lab 7: Neural Networks 1 - NumPy for Building Multi Layers Perceptron (MLP) Advanced Section 5: Generalized Linear Models, Logistic Regression and Beyond R:HW6 - D:HW5 9 Lecture 14: Linear and Quadratic Discriminant Analysis Lecture 15: Classification Trees Lab 8: Discriminant Analysis and Classification Trees Advanced Section 6: Cancelled R:HW7 - D:HW6 10 Lecture 16: Regression Trees Bagging and Random Forest Lecture 17: Boosting Methods Lab 9: Random Forest and Boosting Advanced Section 7: Decision Trees and Ensemble Methods R:HW8 - D:HW7 11 Lecture 18: Neural Networks 2 - Anatomy of NN Lecture 19: Neural Networks 3 - Regularization Methods for NN Lab 10: Neural Networks 2 - Keras for Neural Network Advanced Section 8: Neural Networks for Image Analysis R:HW9(individual) D:HW8 12 Lecture 20: Support Vector Machines (SVM) No Lecture: Thanksgiving No Lab No Advanced Section No Assignment 13 Lecture 21: Stacking Lecture 22: Responsible Data Science - Guest Lecture (Julia Stoyanovich) No Lab Advanced Section 9: Support Vector Machines D:HW9 14 Lecture 23: AB Testing Lecture 24: Final Lecture 15 Reading Period 16 Finals Week","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } List of Contents Course Structure Prerequisites Software Course Activities Recommended Textbook Assignments Getting Help Course Policies Course Structure The material of the course is divided 3 modules. Each module will integrate the five key facets of an investigation using data: Module A: facet a, facet b, facet c, facet d, facet e. Module B: facet a, facet b, facet c, facet d, facet e. Module C: facet a, facet b, facet c, facet d, facet e. Check the schedule for more details on the contents of the course. Prerequisites You are expected to have programming experience at the level of CS 50 or above, and statistics knowledge at the level of Stat 100 or above (Stat 110 recommended). HW0 is designed to test your knowledge on the prerequisites. Successful completion of this assignment will show that this course is suitable for you. HW0 will not be graded but you are required to submit to enroll in the class. Software We will be using Python 3 run on Jupyter Notebooks. You can access the notebook viewer either in your own machine by installing the Anaconda Platform which includes Jupyter/IPython as well all packages that will be required for the course, or by using the SEAS JupyterHub from Canvas. More details in class. Course Activities The course is structured in three different types of activities that repeat themselves each week and they are: Lectures , Labs , and Sections . Lectures are held on Mon and Wed from 1:30-2:45 pm in Northwest Building, Lecture Hall B-103. Attendance is mandatory for FAS students and for DCE students recorded lectures will be available and must be visioned within 2 days after the lectures. There will be quizzes at the end of each lecture to assess the understanding of the material that will help us identify gaps. Lectures will be recorded and made available real time for DCE students and 24 hours later for in-campus students via Canvas. Labs are held on Thur 4:30-6:00 pm and Fri 10:30-11:45 am in Pierce 301. The two labs have identical contents and you should plan to attend one of the two. Attendance is optional , however it is strongly encouraged . Labs are designed as hands-on activities and are useful to practice with problems similar to the homework. Labs will be videotaped only for distant students. Sections are supplementary activities led by teaching fellows to elaborate upon the lectures material. There are two types of sections: 3a. Standard Sections are held on Monday and will cover a blend of lecture material and practice problems. 3b. Advanced Sections are held on Wednesday and will cover advanced topics about mathematical underpinnings of the methods presented in lecture and lab. The Advanced Section material is required for AC209A students . Recommended Textbook An Introduction to Statistical Learning by James, Witten, Hastie, Tibshirani. The book is available here: Free version Hollis Amazon Assignments The final grade will be calculated using the following weights for each assignment: Assignment Final Grade Weight Homework 40% Quizzes 10% Project 50% Total 100% Homework There are 9 homework to complete. There will be an initial self-assessment homework called HW0 and 8 more graded homework assignments. Some of them will be due in a week and some of them in two weeks. You have the option to work and submit the homework in pairs for all the assignments except two which you will do individually. You will be working in Jupyter Notebooks which you can run in your own environment or in the SEAS JupyterHub cloud. The homework are graded on a scale 1 to 5, where 5 is the highest grade. Quizzes There will be a quiz at the end of the class based on what was discussed in lecture. Students will have a limited amount of time to complete the quiz (DCE students will have 72 hours). 40% of the quizzes will be dropped before calculating your final grade. Final Project There will be a final group project (2-4 students) due during Exams period encompassing all the material learned in class. Submitting an Assignment Instructions for turning in assignments will be posted when the semester starts. Grading Guidelines Homework will be graded based on: How correct your code is and whether the cells in your notebook run (we are not troubleshooting code). How you have interpreted the results (we want text not just code). How well you present the results (as you would do in a report). Getting Help For questions about homework, course content, package installation, and after you have tried to troubleshoot yourselves, the process to get help is: Post the question in Piazza and hopefully your peers will answer. Note that in Piazza questions are visible to everyone. The TFs monitor the posts. Go to Office Hours , this is the best way to get help. For private matters send an email to the Helpline: cs109a2018@gmail.com. The Helpline is monitored by TFs. For personal and confidential matters send an email to the instructors . Course Policies Collaboration Policy We encourage you to talk and discuss the assignments with your fellow students (and on Piazza), but you are not allowed to look at any other students assignment or code outside of your pair. Discussion is encouraged, copying is not allowed . Please refer to Academic Honesty in The CS109A Grade linked here The CS109A Grade . Late Day Policy Homework is due on Tuesdays. You are allowed 1 late day per homework for a total of 5 late days. Re-Grading Policy We take great care in making sure all homework are graded properly. However if you feel that your assignment was not fairly graded you may contact the grader by emailing the helpline with subject line \"Regrade HW1: Grader=johnsmith\" within 48 hours of the grade release . If still unhappy with the initial response, then submit a reason via email to the Helpline with subject line \"Regrade HW1: Second request\" within 2 days of receiving the initial response. Important Note: once regrading is done, you may receive a grade that is higher or lower than the initial grade. Communication from Staff to Students Class announcements will be through Canvas . All homework and quizzes will be posted and submitted in Canvas. Also all feedback forms. Important note : make sure you have your settings set so you can receive emails from Canvas. Academic Honesty Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109 we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to Academic Honesty section in The CS109A Grade link above. Accommodations for students with disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with Kevin by the end of the third week of the term: Friday, September 15. Failure to do so may result in us being unable to respond in a timely manner. All discussions will remain confidential.","tags":"pages","url":"pages/syllabus.html"},{"title":"CS109a: Introduction to Data Science","text":"Fall 2019 Pavlos Protopapas and Kevin A. Rader pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } .contentA { flex: 1; flex-direction:column; } .contentB { flex: 3; } Welcome to CS109a/STAT121a/AC209a, also offered by the DCE as CSCI E-109a, Introduction to Data Science. This course is the first half of a one‐year course to data science. We will focus on the analysis of data to perform predictions using statistical and machine learning methods. Topics include data scraping, data management, data visualization, regression and classification methods, and deep neural networks (see the schedule ). You will get ample practice through weekly homework assignments. The class material integrates the five key facets of an investigation using data: 1. data collection ‐ data wrangling, cleaning, and sampling to get a suitable data set 2. data management ‐ accessing data quickly and reliably 3. exploratory data analysis – generating hypotheses and building intuition 4. prediction or statistical learning 5. communication – summarizing results through visualization, stories, and interpretable summaries Only one of CS 109a, AC 209a, or Stat 121a can be taken for credit. Students who have previously taken CS 109, AC 209, or Stat 121 cannot take CS 109a, AC 209a, or Stat 121a for credit. Lectures: Mon and Wed 1:30‐2:45 pm in Harvard Northwest Building, NW B-103 Labs : Thur 4:30-6:00 pm and Fri 10:30-11:45 am in Pierce 301 (content is identical, students should only attend one) Head TFs : Eleni Kaxiras -DCE Head TF : Sol Girouard Office Hours: IACS student lobby in Maxwell-Dworkin's ground. Just follow the signs. Online Office Hours zoom link: https://harvard-dce.zoom.us/j/7607382317 Class meetings have concluded! Thank you all for a great semester! Guest Lecture on Nov 28th: Ethics and Critical Thinking, Julia Stoyanovich , Assistant Professor in the Department of Computer Science and Engineering at the Tandon School of Engineering, and the Center for Data Science. Course material can be viewed in the public GitHub repository . REGULAR SECTIONS Cover the material presented in class. All 2 sessions are identical. Standard Sections have concluded. Thank you! ADVANCED SECTIONS Cover a different topic per week and are required for 209a students. Advanced Sections have concluded. Thank you! Instructor Office Hours Pavlos : Mon. 4:00-5:00 pm Kevin : Mon. 3:00-4:00 pm. TF Office Hours See the Weekly Schedule Please be aware, that we will not publicly release the homework assignments this year. If you want to follow the course online without registering, you can use the assignments from 2013 and 2014, available at the links below. Additionally, the material from 2015 is also available. Previous Material 2017 2015 2014 . 2013","tags":"pages","url":"pages/cs109a-introduction-to-data-science/"},{"title":"Advanced Sections 1:","text":"Slides","tags":"a-section","url":"a-section/a-section1/"},{"title":"Advanced Sections 2:","text":"Slides","tags":"a-section","url":"a-section/a-section2/"},{"title":"Advanced Sections 3:","text":"Slides","tags":"a-section","url":"a-section/a-section3/"},{"title":"Advanced Sections 4:","text":"Slides","tags":"a-section","url":"a-section/a-section4/"},{"title":"Advanced Sections 5:","text":"Slides","tags":"a-section","url":"a-section/a-section5/"},{"title":"Advanced Sections 6:","text":"Slides","tags":"a-section","url":"a-section/a-section6/"},{"title":"Lab 1:","text":"Slides","tags":"labs","url":"labs/lab1/"},{"title":"Lab 10:","text":"Slides","tags":"labs","url":"labs/lab10/"},{"title":"Lab 11:","text":"Slides","tags":"labs","url":"labs/lab11/"},{"title":"Lab 12:","text":"Slides","tags":"labs","url":"labs/lab12/"},{"title":"Lab 13:","text":"Slides","tags":"labs","url":"labs/lab13/"},{"title":"Lab 2:","text":"Slides","tags":"labs","url":"labs/lab2/"},{"title":"Lab 3:","text":"Slides","tags":"labs","url":"labs/lab3/"},{"title":"Lab 4:","text":"Slides","tags":"labs","url":"labs/lab4/"},{"title":"Lab 5:","text":"Slides","tags":"labs","url":"labs/lab5/"},{"title":"Lab 6:","text":"Slides","tags":"labs","url":"labs/lab6/"},{"title":"Lab 7:","text":"Slides","tags":"labs","url":"labs/lab7/"},{"title":"Lab 8:","text":"Slides","tags":"labs","url":"labs/lab8/"},{"title":"Lab 9:","text":"Slides","tags":"labs","url":"labs/lab9/"},{"title":"Lecture 1:","text":"Slides","tags":"lectures","url":"lectures/lecture1/"},{"title":"Lecture 10:","text":"Slides","tags":"lectures","url":"lectures/lecture10/"},{"title":"Lecture 11:","text":"Slides","tags":"lectures","url":"lectures/lecture11/"},{"title":"Lecture 12:","text":"Slides","tags":"lectures","url":"lectures/lecture12/"},{"title":"Lecture 13:","text":"Slides","tags":"lectures","url":"lectures/lecture13/"},{"title":"Lecture 14:","text":"Slides","tags":"lectures","url":"lectures/lecture14/"},{"title":"Lecture 15:","text":"Slides","tags":"lectures","url":"lectures/lecture15/"},{"title":"Lecture 16:","text":"Slides","tags":"lectures","url":"lectures/lecture16/"},{"title":"Lecture 17:","text":"Slides","tags":"lectures","url":"lectures/lecture17/"},{"title":"Lecture 18:","text":"Slides","tags":"lectures","url":"lectures/lecture18/"},{"title":"Lecture 19:","text":"Slides","tags":"lectures","url":"lectures/lecture19/"},{"title":"Lecture 2:","text":"Slides","tags":"lectures","url":"lectures/lecture2/"},{"title":"Lecture 20:","text":"Slides","tags":"lectures","url":"lectures/lecture20/"},{"title":"Lecture 21:","text":"Slides","tags":"lectures","url":"lectures/lecture21/"},{"title":"Lecture 22:","text":"Slides","tags":"lectures","url":"lectures/lecture22/"},{"title":"Lecture 23:","text":"Slides","tags":"lectures","url":"lectures/lecture23/"},{"title":"Lecture 24:","text":"Slides","tags":"lectures","url":"lectures/lecture24/"},{"title":"Lecture 3:","text":"Slides","tags":"lectures","url":"lectures/lecture3/"},{"title":"Lecture 4:","text":"Slides","tags":"lectures","url":"lectures/lecture4/"},{"title":"Lecture 5:","text":"Slides","tags":"lectures","url":"lectures/lecture5/"},{"title":"Lecture 6:","text":"Slides","tags":"lectures","url":"lectures/lecture6/"},{"title":"Lecture 7:","text":"Slides","tags":"lectures","url":"lectures/lecture7/"},{"title":"Lecture 8:","text":"Slides","tags":"lectures","url":"lectures/lecture8/"},{"title":"Lecture 9:","text":"Slides","tags":"lectures","url":"lectures/lecture9/"},{"title":"Sections 1:","text":"Slides","tags":"section","url":"section/section1/"},{"title":"Sections 10:","text":"Slides","tags":"section","url":"section/section10/"},{"title":"Sections 11:","text":"Slides","tags":"section","url":"section/section11/"},{"title":"Sections 12:","text":"Slides","tags":"section","url":"section/section12/"},{"title":"Sections 13:","text":"Slides","tags":"section","url":"section/section13/"},{"title":"Sections 2:","text":"Slides","tags":"section","url":"section/section2/"},{"title":"Sections 3:","text":"Slides","tags":"section","url":"section/section3/"},{"title":"Sections 4:","text":"Slides","tags":"section","url":"section/section4/"},{"title":"Sections 5:","text":"Slides","tags":"section","url":"section/section5/"},{"title":"Sections 6:","text":"Slides","tags":"section","url":"section/section6/"},{"title":"Sections 7:","text":"Slides","tags":"section","url":"section/section7/"},{"title":"Sections 8:","text":"Slides","tags":"section","url":"section/section8/"},{"title":"Sections 9:","text":"Slides","tags":"section","url":"section/section9/"}]}